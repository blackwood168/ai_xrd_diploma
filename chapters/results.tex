\section{Результаты и обсуждение}

В рамках данной работы был разработан автоматизированный конвейер (пайплайн), позволяющий проводить воспроизводимые эксперименты по решению проблемы фаз с помощью предложенного подхода (\url{github.com/blackwood168/xrd_phase_ml}, рис. \ref{pipeline}). В нем реализовано обучение и тестирование моделей, а также получение результатов (inference) на реальных массивах данных и структурах кристаллических соединений. В репозитории присутствуют маленькие наборы данных из сгенерированных и реальных структур малых органических молекул, также там представлены веса обученных в работе моделей. Воспроизводимость обучения обеспечивает фиксирование начальных значений генераторов случайных состояний.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figures/pipeline.png}
    \caption{Схема разработанного автоматизированного контейнера, использующего модели глубокого обучения (DL) для предсказывания амплитуд структурных факторов}
    \label{pipeline}
\end{figure}


\subsection{Решение для структурных факторов (разрешение 1.5\angstrom)}

\subsubsection{Результаты обучения}

Было проведено обучение на синтетических данных (набор $D_1$) и последующее дообучение на рентгенодифракционных данных реальных структур из Кембриджской Базы Структурных Данных (CSD). В ходе обучения модель повышала разрешение с 1.5 до 0.8 \angstrom. Сравнение R--фактора для моделей до и после дообучения представлено в таблице \ref{doposle}. После дообучение на реальных данных точность предсказания моделей увеличивается минимум на треть, однако теряется точность на синтетических данных, кроме UNet с Фурье-преобразованием, который лишь прибавляет в точности на сгенерированных структурах после дообучения на реальных. Лучшую точность имеет модель UNet\_FFT (R=0.336), от которой немного отстает трансформер. В сводной таблице \ref{svod} представлены значения метрик на реальных данных финальных моделей. Таким образом, UNet\_FFT занимает меньше видеопамяти, работает быстрее и достигает лучшей метрики на тестовых реальных данных.

\begin{table}[H]
\caption{Результаты обучения и эффективность дообучения моделей, повышающих разрешение с 1.5 до 0.8 \angstrom (синт.~---~синтетические тестовые данные)}
\label{doposle}
\centering
\footnotesize
\begin{tabular}{|l|l|l|l|} 
\hline
\textbf{Модель} & \textbf{Метрика} & \textbf{Синт.} & \textbf{CSD}  \\ 
\hline
\multirow{3}{*}{UNet} 
& До, R & 0.477 & 0.590 \\ 
& После, R  & 0.632 & 0.393 \\ 
& $\Delta$, \%       & -32.6 & 33.4  \\
\hline
\multirow{3}{*}{FFT\_UNet}
& До, R & 0.726 & 0.646 \\ 
& После, R  & 0.619 & \textbf{0.336} \\ 
& $\Delta$, \%       & 14.7  & 48.0  \\
\hline
\multirow{3}{*}{XRD\_Transformer}
& До, R & 0.346 & 0.581 \\ 
& После, R  & 0.615 & 0.358 \\ 
& $\Delta$, \%       & -77.9 & 38.4  \\
\hline
\end{tabular}
\end{table}



\begin{table}[H]
\centering
\caption{Значения метрик на тестовом реальном наборе данных моделей, повышающих разрешение с 1.5 до 0.8 \angstrom после дообучения}
\label{svod}
\begin{tabular}{|c|c|c|c|} 
\hline
\diagbox{\textbf{Metric}}{\textbf{Model}} & \textbf{UNet} & \textbf{FFT\_UNet} & \textbf{XRD\_Transformer}  \\ 
\hline
MSE$\cdot10^{-3}$                               & 1,39      & 1,20           & 1,31                   \\ 
\hline
R                                & 0,393         & \textbf{0,336}              & 0,358                      \\
\hline
\end{tabular}
\end{table}




\subsubsection{Определение структур}

Модели демонстрируют достаточно большие значения R--фактора на реальных моноклинных структурах из Кембриджского Банка Структурных данных, качество восстановления тензора отражений даже после дообучения недостаточно для решения структуры с помощью программы SHELXT. На рис. \ref{recon_ex} представлены характерные сечения тензора отражений для реальной структуры, где R-фактор восстановленного тензора с помощью FFT\_UNet составляет 0.343, но SHELXT с помощью метода Паттерсона не смог определить кристаллическую структуру по таким данным.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figures/real.png}
    \caption{Типичное восстановление дифракционной картины реальной структуры, $R = 0.343$ (с 1.5 до 0.8 \angstrom, усреднено по индексу l)}
    \label{recon_ex}
\end{figure}

Можно заметить, что изображение восстановленного тензора отражений по сравнению с истинным размытое, что можно объяснить результатом минимизации среднеквадратичной ошибки. Поскольку дифракционная картина не является локально связанной, как изображения, соседние пиксели могут сильно различаться. Модели машинного обучения не могут точно предсказать значение амплитуды структурного фактора в каждом пикселе, но справляются с вычислением среднего значения. Стоит отметить, что несмотря на низкую точность решения поставленной задачи регрессии, модель достаточно точно определяет границы дифракционной картины, то есть какие отражения будут ненулевые в тензоре отражений более высокого разрешения.

\subsection{Решение для структурных факторов (разрешение 1.2\angstrom)}


\subsubsection{Результаты обучения}

Было проведено обучение на синтетических данных (набор $D_2$) и последующее дообучение на реальных моделей, повышающих разрешение дифракционной картины с 1.2 до 1.0 \angstrom. Сравнение R--фактора для моделей до и после дообучения представлено в таблице \ref{doposle2}. После дообучение на настоящих органических структурах из CSD точность предсказания дифракционных максимумов для структур увеличивается больше всего для UNet с Фурье--преобразованием --- более чем на треть. Лучшую точность показывает UNet\_FFT (R=0.336), от которой немного отстает UNet. На этот раз трансформер показывает худший результат на реальных структурах. В сводной таблице \ref{svod2} представлены значения метрик на реальных данных финальных моделей. Таким образом, UNet\_FFT снова становится наиболее точной моделью машинного обучения для увеличения разрешения дифракционной картины. В дальнейшем для проблемы фаз будет использоваться именно эта модель.

\begin{table}[H]
\caption{Результаты обучения и эффективность дообучения моделей, повышающих разрешение с 1.2 до 1.0 \angstrom (синт.~---~синтетические тестовые данные)}
\label{doposle2}
\centering
\footnotesize
\begin{tabular}{|l|l|l|l|} 
\hline
\textbf{Модель} & \textbf{Метрика} & \textbf{Синт.} & \textbf{CSD}  \\ 
\hline
\multirow{3}{*}{UNet} 
& До, R & 0.119 & 0.255 \\ 
& После, R  & 0.109 & 0.207 \\ 
& $\Delta$, \%       & 8.4 & 18.8  \\
\hline
\multirow{3}{*}{FFT\_UNet}
& До, R & 0.107 & 0.234 \\ 
& После, R  & 0.319 & \textbf{0.152} \\ 
& $\Delta$, \%       & -198.1  & 35.0  \\
\hline
\multirow{3}{*}{XRD\_Transformer}
& До, R & 0.236 & 0.337 \\ 
& После, R  & 0.104 & 0.267 \\ 
& $\Delta$, \%       & 55.9 & 26.2  \\
\hline
\end{tabular}
\end{table}


\begin{table}[H]
\centering
\caption{Значения метрик на тестовом реальном наборе данных моделей, повышающих разрешение с 1.2 до 1.0 \angstrom после дообучения}
\label{svod2}
\begin{tabular}{|c|c|c|c|} 
\hline
\diagbox{\textbf{Метрика}}{\textbf{Модель}} & \textbf{UNet} & \textbf{FFT\_UNet} & \textbf{XRD\_Transformer}  \\ 
\hline
MSE$\cdot10^{-3}$                               & 0.684      & 0.489           & 0.199                   \\ 
\hline
R                                & 0.207         & \textbf{0.152}              & 0.267                      \\
\hline
\end{tabular}
\end{table}

%\subsubsection{Анализ моделей}

\subsubsection{Определение структур}

Несмотря на низкие значения R--факторов, посчитанных при сравнении дифракционной картины, восстановленой нейронной сетью FFT\_UNet, и данных, рассчитанных по реальным структурам (рис. \ref{restor12}), качества данных для определения структуры методом Паттерсона с помощью программного обеспечения SHELXT все еще не хватает. Так, лишь для 83\% низкомолекулярных органических структур из CSD, выбранных в качестве тестовой выборки, метод нашёл какое-то подходящее решение, средний R--фактор по таким структурам равен 0.49. Структуры, чьё решение имеет R--фактор не более 0.25, составляют 10\% всей тестовой выборки. Для сравнения~--- если попытаться решить структуры с помощью рентгенодифракционных данных, рассчитанных по структуре, с разрешением 1.0 \angstrom , SHELXT выдаёт решение для 97\% структур со средним R--фактором равным 0.13. Результаты представлены в таблице \ref{restor12tabl}.


\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figures/restor12.png}
    \caption{Типичное восстановление дифракционной картины реальной структуры, $R = 0.133$ (с 1.2 до 1.0 \angstrom, усреднено по индексу l)}
    \label{restor12}
\end{figure}


\begin{table}[H]
\caption{Данные по эффективности определения решения по рентгенодифракционным данным с разрешением 1.0\angstrom , полученных с помощью ИИ, и рассчитанным по структуре}
\label{restor12tabl}
\centering
\begin{tabular}{|c|c|c|c|} 
\hline
\diagbox{\textbf{Показатель}}{\textbf{Данные}} & \textbf{Восстановленные (ИИ)} & \textbf{Рассчитанные}  \\ 
\hline
Наличие решений, \%                               & 83      & 97                          \\ 
\hline
Наличие решений с $R\leq 0.25$, \%                                & 10         & 94                               \\
\hline
Средний R                                          & 0.49                & 0.13                 \\
\hline
\end{tabular}
\end{table}



\subsection{Решение для нормализованных структурных факторов}

\subsubsection{Результаты обучения}

\subsubsection{Определение структур}

\subsection{Анализ моделей}

Для более глубокого понимания трансформера был проведен анализ внутренней работы модели. Особый интерес представляют карты внимания (рис. \ref{attention_maps}), которые визуализируют, как модель распределяет свое внимание при обработке дифракционных данных тестовой реальной кристаллической структуры. Механизм внимания в трансформере позволяет модели определять, какие части входных данных наиболее важны для принятия решения в каждый момент времени. В первых слоях трансформера внимание распределено равномерно и рассеянно по всей структуре данных. Это соответствует этапу сбора общего контекста, когда модель пытается получить целостное представление о кристаллической структуре. В последующих слоях внимание становится более сфокусированным и локализованным, что указывает на то, что модель научилась выделять специфические взаимосвязи между различными частями данных. Важно отметить способность модели устанавливать связи между отражениями, находящимися на значительном расстоянии друг от друга в обратном пространстве. Это критически важно для решения проблемы фаз, так как часто ключевые взаимосвязи существуют между отражениями, которые не являются ближайшими соседями. Кроме того, наблюдаются характерные диагональные паттерны внимания, которые коррелируют с известными систематическими погасаниями в кристаллографии. Можно предположить, что модель глубокого обучения без явного указания из обучающей выборки выучила механизм погасаний.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figures/attention.png}
    \caption{Связи внимания в блоках трансформера}
    \label{attention_maps}
\end{figure}

Для количественного подтверждения этой гипотезы, было проанализировано распределение значений внимания для наиболее сильных связей в каждом блоке трансформера (рис. \ref{attention_maps}). Особый интерес представляет сравнение двух типов связей: между точками, соответствующим систематическим погасаниям и обычными отражениями. Можно заметить, что во время сбора общего контекста в первом блоке распределение значений внимания для связей с погасшими отражениями сопоставимо с таковым для обычных отражений. Это логично, поскольку на этом этапе модель еще не дифференцирует типы отражений, а просто собирает общую информацию о структуре. Однако уже во втором блоке наблюдается значительно уменьшение связей внимания, соединяющих погасания. Это указывает на то, что модель начинает осознавать, что эти отражения несут меньше полезной информации, требуемой для предсказывания дальних отражений. В третьем же блоке модель игнорирует точки обратного пространства, соответствующие систематическим погасаниям, и в выходном тензоре на соответствующих местах стоят нули. 

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figures/attention_hist.png}
    \caption{Распределение величин внимания в первых блоках трансформера}
    \label{attention_maps}
\end{figure}

Такое поведение модели демонстрирует, что она не просто запомнила шаблоны из обучающей выборки, а научилась автоматически определять и игнорировать отражения, соответствующие систематическим погасаниям (если такие присутствуют). Трансформер действительно успешно выучил кристаллографическую закономерность, значит, данная архитектура может являться ключевой для дальнейших исследований применения методов глубокого обучения для решений кристаллографических задач.

Для понимания внутренней работы моделей на основе UNet, был проведен анализ первого блока обеих архитектур с помощью метода GradCAM (рис. \ref{gradcam}) \cite{selvaraju_grad-cam_2020}. Этот метод позволяет визуализировать, какие области входных данных имеют наибольшее влияние для принятия решений моделью.


\begin{figure}[H]
     \centering
     \includegraphics[width=1\textwidth]{figures/attribute_map.png}
     \caption{Тепловые карты влияния GradCAM (усреднено по индексу l)}
     \label{gradcam}
\end{figure}

%\begin{figure}[H]
%    \centering
%    \includegraphics[width=1\textwidth]{figures/attribution_overlay.png}
%    \caption{Анализ первого блока UNet с помощью GradCAM}
%    \label{gradU}
%\end{figure}
%
%\begin{figure}[H]
%    \centering
%    \includegraphics[width=1\textwidth]{figures/attribution_overlay_fft.png}
%    \caption{Анализ первого блока FFT\_UNet с помощью GradCAM}
%    \label{gradFFT}
%\end{figure}

Анализ тепловой карты влияния для модели UNet показал интересную особенность: модель концентрируется во всем пространстве за пределами изначальной дифракционной картины низкого разрешения. Это может указывать на то, что модель UNet не полностью учитывает физические ограничения задачи и пытается извлечь информацию из областей, где она физически не может существовать. 

В отличие от UNet, паттерн внимания для FFT\_UNet выглядит более физически обоснованным. Значения влияния распространяются преимущественно на область входной дифракционной картины и немного выходят за её границы. Это поведение более физически обосновано, так как модель ищет информацию вблизи границ дифракционной картины, где могут находиться важные детали структуры. 

Это различие в поведении моделей может объяснять, почему FFT\_UNet показывает лучшие результаты в восстановлении дифракционной картины. Её способность более точно определять области, где может находиться полезная информация, и игнорировать физически нереалистичные области, делает её более эффективной в поиске правильного решения.



\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figures/sensitivity.png}
    \caption{Тепловые карты чувствительности, усреднено по индексу l}
    \label{sens}
\end{figure}


Для оценки устойчивости моделей к шуму в экспериментальных данных был проведен анализ карт чувствительности (рис. \ref{sens}). Карты чувствительности показывают, как сильно меняется выход модели при добавлении случайного шума к входным данным, что позволяет оценить устойчивость модели в различных областях обратного пространства. Базовая модель UNet демонстрирует неустойчивое поведение – выход модели может измениться при добавлении шума на очень большие значения. Модель с Фурье-преобразованием FFT\_UNet стабильно работает при наличии шума в данных. Высокая робастность в большей части пространства указывает на то, что модель научилась извлекать надежные признаки из данных и не переобучилась на конкретные значения амплитуд структурных факторов. 


Анализ результатов показывает, что нейронная сеть успешно справляется с определением общих характеристик дифракционной картины. Она точно предсказывает границы дифракционной картины и корректно восстанавливает средние значения амплитуд структурных факторов по небольшим областям. Однако изменения амплитуд между соседними точками обратного пространства недостаточно четко выражены, что приводит к потере важных деталей в распределении амплитуд. 

Это ограничение становится особенно критичным, если учесть фундаментальную особенность дифракционных отражений: каждое отражение содержит информацию о всей кристаллической структуре, и для успешного решения проблемы фаз необходимо чрезвычайно точное определение амплитуды в каждой точке. Хотя модели глубокого обучения выявляют некоторые кристаллографические закономерности, они не достигают необходимой точности в численном определении значений для каждой точки.

Таким образом, методы глубокого обучения демонстрируют значительный потенциал в распознавании кристаллографических закономерностей в обратном пространстве, но сталкиваются с фундаментальным ограничением при решении проблемы фаз. Это ограничение связано с необходимостью чрезвычайно точного численного восстановления амплитуд отражений, что требует более точного подхода к определению значений в каждой точке. Это наблюдение указывает на необходимость разработки новых архитектур или подходов, которые могли бы сочетать способность к распознаванию паттернов с более точным численным восстановлением.


%\subsection{Дальнейшие планы и предложения}

%Было показано, что методы глубокого обучения успешно схватывают кристаллографические закономерности, однако из-за специфики обратного пространства для решения проблемы фаз им не хватает точности. Совершив переход в прямое пространство, можно предположить, что нейронные сети справятся с поставленной задачей.

%Для решения проблемы фаз часто используется функция Паттерсона:

%\begin{center}
%    $P(u, v, w) = \sum\limits_{h,k,l\in Z} |F(h,k,l)|^2e^{-2\pi i(hu+kv+lw)}$
%\end{center}

%Функция Паттерсона является Фурье-преобразованием интенсивностей дифракционных максимумов, где за их фазы приняты нули. Таким образом, перейдя от тензора отражений к карте функции Паттерсона - получается классическая задача повышения разрешения изображений, поскольку для дифракционной картины низкого разрешения получится Фурье-образ низкого разрешения, разрешение которого требуется повысить так, чтобы восстановленная картина соответствовала Фурье-образу дифракционной картины высокого разрешения. После увеличения разрешения трехмерной картины функции Паттерсона, мы можем вернуться в обратное пространство, рассчитав интенсивности (и из них амплитуды) рентгенодифракционных отражений, и решить проблему фаз с помощью уже существующих ab initio методов.

%\begin{figure}[H]
%    \centering
%    \includegraphics[width=0.5\textwidth]{figures/patt_high.png}\hfill
%    \includegraphics[width=0.5\textwidth]{figures/patt_low.png}
%    \caption{Типичное сечение функции Паттерсона по данным низкого (слева) и высокого (справа) разрешения}
%    \label{patt}
%\end{figure}